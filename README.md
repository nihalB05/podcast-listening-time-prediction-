# podcast-listening-time-prediction-

ğŸ§ Podcast Listening Time Prediction ğŸš€

A Machine Learning project to predict user listening duration (in minutes) for podcast episodes based on content, metadata, and engagement metrics. Built for competition-level performance with deep feature engineering and robust model optimization.
ğŸ“Œ Project Overview

In this project, we aim to predict how long users will listen to a podcast episode. The dataset contains metadata like episode length, genre, guest/host popularity, and sentiment.

We tackled the task using:

âœ… Manual & custom preprocessing
âœ… Feature engineering (cyclical time, interaction terms, podcast-level stats)
âœ… Advanced modeling with XGBoost and ensemble stacking
âœ… Cross-validation and hyperparameter tuning
âœ… Competition-style predictions with optimized RMSE performance
ğŸ“‚ Dataset Summary
Column	Description
Episode_Length_minutes	Duration of the episode
Genre, Publication_Day	Categorical metadata
Host/Guest_Popularity	Popularity indicators
Number_of_Ads	Ad count per episode
Episode_Sentiment	Sentiment polarity
Listening_Time_minutes	ğŸš¨ Target variable
ğŸ”§ Preprocessing Highlights

We implemented:

    Manual preprocessing for categorical and numeric features

    Missing value imputation with indicators

    Encoding strategies: One-hot, label encoding, and OOF mean encoding

    Cyclical time encoding (hour_sin, hour_cos)

    Feature interactions:

        Host Ã— Guest Popularity

        Ads per Minute, Length Ã— Ads

        Weekend Ã— Time of Day

ğŸ§  Modeling Approach
âœ… Models Used:

    XGBoost Regressor ğŸ”¥

    LightGBM & CatBoost for stacking

    Ridge as meta-model (stacking layer)

âš™ï¸ Optimization:

    5-Fold Cross-Validation

    RandomizedSearchCV for tuning

    Ensemble stacking for final predictions

ğŸ“‰ Evaluation Metric:

    Root Mean Squared Error (RMSE)

    Best RMSE achieved (CV): ~13.07

    Benchmark leaderboard RMSE: 11.44

ğŸ“ˆ Key Results & Learnings

    âš™ï¸ Engineering OOF target means for podcasts added significant lift

    ğŸ§© Interactions + time features reduced overfitting

    ğŸ§ª Stacking consistently outperformed single models

    ğŸ¯ Final submission was robust and close to the top leaderboard entries

ğŸ“ Folder Structure

ğŸ“¦ podcast-listening-prediction/
â”‚
â”œâ”€â”€ ğŸ“˜ README.md
â”œâ”€â”€ ğŸ“’ pplt.ipynb              # Main notebook
â”œâ”€â”€ ğŸ“Š submission.csv          # Final output
â”œâ”€â”€ ğŸ“ data/                   # Train & test datasets
â””â”€â”€ ğŸ“ requirements.txt        # Required libraries

ğŸš€ How to Run

    Clone the repo

git clone https://github.com/yourname/podcast-listen-time
cd podcast-listen-time

Install dependencies

    pip install -r requirements.txt

    Run the notebook
    Open pplt.ipynb in Jupyter Notebook or VS Code and execute step-by-step.

ğŸ“Œ Future Improvements

    Add NLP-based sentiment reanalysis from titles

    Use audio metadata (if available)

    Try neural networks (MLP or TabNet)

    Add SHAP explainability

ğŸ§  Author

Your Name â€” Data Science Enthusiast | ML Explorer ğŸš€
Feel free to connect or contribute ideas!
